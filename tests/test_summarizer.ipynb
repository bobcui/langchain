{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['https://finance.yahoo.com/news/prediction-artificial-intelligence-ai-company-220000588.html', 'https://finance.yahoo.com/news/tesla-inc-tsla-among-best-202341203.html', 'https://seekingalpha.com/news/4426704-tesla-shorts-make-10b-ytd-short-interest-rebounds-to-81m-shares']\n"
     ]
    }
   ],
   "source": [
    "def get_marketaux_news(company_name: str) -> str:\n",
    "\n",
    "    import requests\n",
    "    \n",
    "    API_KEY = \"your_marketaux_api_key\"\n",
    "    url = \"https://api.marketaux.com/v1/news/all\"\n",
    "    params = {\n",
    "        \"api_token\": \"A3k62V7qsceE4p8tM4hTO053p1RxjcVJ8xqdy0zV\",\n",
    "        \"symbols\": company_name,\n",
    "        \"language\": \"en\",\n",
    "        \"limit\": 5\n",
    "    }\n",
    "    response = requests.get(url, params=params)\n",
    "    data = response.json()\n",
    "    if \"data\" in data:\n",
    "        return [article[\"url\"] for article in data[\"data\"]]\n",
    "    else:\n",
    "        return []\n",
    "\n",
    "\n",
    "company_name = \"TSLA\"\n",
    "\n",
    "news_urls = get_marketaux_news(company_name)\n",
    "print(news_urls)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error scraping article: Article `download()` failed with 403 Client Error: Forbidden for url: https://seekingalpha.com/news/4426704-tesla-shorts-make-10b-ytd-short-interest-rebounds-to-81m-shares on URL https://seekingalpha.com/news/4426704-tesla-shorts-make-10b-ytd-short-interest-rebounds-to-81m-shares\n"
     ]
    }
   ],
   "source": [
    "def scrape_article(url: str) -> str:\n",
    "    from newspaper import Article\n",
    "\n",
    "    try:\n",
    "        article = Article(url)\n",
    "        article.download()\n",
    "        article.parse()\n",
    "        return {\n",
    "            \"title\": article.title,\n",
    "            \"content\": article.text,\n",
    "        }\n",
    "    except Exception as e:\n",
    "        print(f\"Error scraping article: {e}\")\n",
    "        return {\n",
    "            \"title\": \"\",\n",
    "            \"content\": \"\",\n",
    "        }\n",
    "\n",
    "articles = [scrape_article(url) for url in news_urls]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "title:Prediction: This Artificial Intelligence (AI) Company Will Be the Biggest Beneficiary of Self-Driving Vehicles (Hint: It's Not Tesla) len:2586\n",
      "title:Tesla, Inc. (TSLA): Among the Best Robotics Stocks to Buy According to Billionaires len:2983\n",
      "title: len:0\n"
     ]
    }
   ],
   "source": [
    "for article in articles:\n",
    "    print(f\"title:{article['title']} len:{len(article['content'])}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.prompts import PromptTemplate\n",
    "from langchain.chains import LLMChain\n",
    "from langchain.llms import BaseLLM\n",
    "from langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder\n",
    "from langchain_core.messages import HumanMessage\n",
    "\n",
    "def get_summary_from_llm(llm: BaseLLM, config: dict, article_title: str, article_content: str) -> str:\n",
    "    prompt = f\"\"\"you are a professional journalist who has been asked to analyze the following article and provide a summary, sentiment analysis, and key points.\n",
    "        Analyze the following article and provide a summary, sentiment analysis, and key points:\n",
    "\n",
    "        Title: {article_title}\n",
    "        Content: {article_content}\n",
    "\n",
    "        Please provide your analysis in the following format:\n",
    "        \n",
    "        Sentiment: The overall sentiment score (positive:10, negative:1, or neutral:5)\n",
    "        Summary: A concise summary of the article (2-3 sentences)\n",
    "        \n",
    "    \"\"\"\n",
    "\n",
    "    return llm.invoke(input=prompt, config=config).content\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def get_human_message(article_title: str, article_content: str) -> str:\n",
    "    prompt = f\"\"\"you are a professional journalist who has been asked to analyze the following article and provide a summary, sentiment analysis, and key points.\n",
    "        Analyze the following article and provide a summary, sentiment analysis, and key points:\n",
    "\n",
    "        Title: {article_title}\n",
    "        Content: {article_content}\n",
    "\n",
    "        Please provide your analysis in the following format:\n",
    "        \n",
    "        Sentiment: The overall sentiment score (positive:10, negative:1, or neutral:5)\n",
    "        Summary: A concise summary of the article (2-3 sentences)\n",
    "        Key Points: The key points of the article (3-5 bullet points)\n",
    "        \n",
    "    \"\"\"\n",
    "    return prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/v_/495_mfbd4rv76fxlb3w_3hs80000gn/T/ipykernel_92536/2875842115.py:7: UserWarning: WARNING! store is not default parameter.\n",
      "                store was transferred to model_kwargs.\n",
      "                Please confirm that store is what you intended.\n",
      "  llm = init_chat_model(\"gpt-4o-mini\", model_provider=\"openai\", store=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--1--\n",
      "\n",
      "Title: Prediction: This Artificial Intelligence (AI) Company Will Be the Biggest Beneficiary of Self-Driving Vehicles (Hint: It's Not Tesla)\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "**Sentiment:** Positive (8/10)\n",
      "\n",
      "**Summary:** The article highlights Nvidia's significant role in the automotive industry, positioning it as a leading beneficiary of advancements in self-driving vehicles, surpassing Tesla. It discusses Nvidia's innovative technology offerings, including AI-driven platforms for vehicle simulation and manufacturing efficiency, and outlines the company’s various partnerships with major automotive players.\n",
      "\n",
      "**Key Points:**\n",
      "- Nvidia is emerging as a powerful player in the automotive sector, providing AI solutions to improve safety and manufacturing processes.\n",
      "- The company’s Omniverse platform allows for the creation of digital twins to simulate vehicle functionality in different environments.\n",
      "- Nvidia has partnered with General Motors to implement AI-powered systems, demonstrating a strong commitment to automotive technology.\n",
      "- Revenue from Nvidia’s automotive segment increased by 55% year-over-year in 2024, indicating robust growth despite representing a small portion of total revenue.\n",
      "- Nvidia works with several major automotive brands, enhancing its influence as self-driving technology evolves.\n",
      "\n",
      "--2--\n",
      "\n",
      "Title: Tesla, Inc. (TSLA): Among the Best Robotics Stocks to Buy According to Billionaires\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "**Sentiment:** Positive (7/10)\n",
      "\n",
      "**Summary:** The article highlights Tesla, Inc. as one of the top robotics stocks favored by billionaires, amidst a growing global robotics market driven by advancements in AI technology. The piece discusses the significant projections for the humanoid robotics market and the overall growth of the robotics industry, especially in Asia, while acknowledging the challenges faced by the broader stock market.\n",
      "\n",
      "**Key Points:**\n",
      "- The robotics industry is rapidly evolving, with the humanoid robot market projected to grow from $6 billion in 2023 to over $38 billion by 2035, according to Goldman Sachs.\n",
      "- Major firms like Morgan Stanley and Citigroup predict a significant increase in humanoid robot units, with expectations for a multi-trillion-dollar market by 2050.\n",
      "- Tesla is recognized as one of the best robotics stocks to invest in, favored by many billionaires, reflecting confidence in its future in the robotics and automation space.\n",
      "- Despite political and economic pressures causing a downturn in the broader U.S. market, robotics stocks are seen as promising due to rising demand for automation.\n",
      "- Asia is the leading region for robotics installations, particularly China, which accounts for over half of the global robot installations in 2023.\n",
      "\n",
      "--3--\n",
      "\n",
      "Skipping article '' due to empty content.\n"
     ]
    }
   ],
   "source": [
    "from langchain.chat_models import init_chat_model\n",
    "from langgraph.checkpoint.memory import MemorySaver\n",
    "from langgraph.checkpoint.memory import MemorySaver\n",
    "from langgraph.graph import START, MessagesState, StateGraph\n",
    "\n",
    "config = {\"configurable\": {\"thread_id\": \"1234\"}}\n",
    "llm = init_chat_model(\"gpt-4o-mini\", model_provider=\"openai\", store=True)\n",
    "\n",
    "workflow = StateGraph(state_schema=MessagesState)\n",
    "\n",
    "def call_model(state: MessagesState):\n",
    "    response = llm.invoke(state[\"messages\"])\n",
    "    return {\"messages\": response}\n",
    "\n",
    "\n",
    "# Define the (single) node in the graph\n",
    "workflow.add_edge(START, \"model\")\n",
    "workflow.add_node(\"model\", call_model)\n",
    "\n",
    "# Add memory\n",
    "memory = MemorySaver()\n",
    "app = workflow.compile(checkpointer=memory)\n",
    "\n",
    "i = 0\n",
    "for article in articles:\n",
    "    i = i+1\n",
    "    print(f\"\\n--{i}--\\n\")\n",
    "\n",
    "    if article['content']:\n",
    "        print(f\"Title: {article['title']}\")\n",
    "        \n",
    "        input_messages = [HumanMessage(get_human_message(article['title'], article['content']))]\n",
    "        output = app.invoke({\"messages\": input_messages}, config)\n",
    "        output[\"messages\"][-1].pretty_print()\n",
    "        \n",
    "    else:\n",
    "        print(f\"Skipping article '{article['title']}' due to empty content.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "8/10\n"
     ]
    }
   ],
   "source": [
    "prompt = \"What's your overall sentiment about these articles? (positive:10, negative:1, or neutral:5). Only Score/10 is required.\"\n",
    "\n",
    "input_messages = [HumanMessage(prompt)]\n",
    "output = app.invoke({\"messages\": input_messages}, config)\n",
    "output[\"messages\"][-1].pretty_print()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
